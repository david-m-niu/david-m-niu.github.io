---
layout: post
title:  "Basic Properties of Measure and Integration"
author: "Yours Truly"
tags: [math, measure theory]
---

I needed to organize various facts relating to measure and integration, not least because I have an exam coming up&hellip;

Because I'm trying to actually make sense of the material, I'll try to verbalize as much as possible while refraining from symbolic language. There are three important theorems. The monotone convergence theorem allows us to switch the limit and integral of a monotonically increasing sequence in $L^+$. Fatou's lemma says that $\int \lim \inf f_n \leq \lim \inf \int f_n$ if $\{f_n\} \subset L^+$. The dominate convergence theorem again allows us to switch the limit and integral of a sequence, this time in $L^1$, as long as it converges a.e. and its absolute value is bounded a.e. by a function $g \in L^1$; in addition, the limit itself is also in $L^1$.

Next, I'll touch on various modes of convergence. Convergence uniformly, pointwise, and a.e. are self-explainatory, with their strengths in decreasing order. Convergence in $L^1$ simply means that $\int \|f_n - f\| \rightarrow 0$, while convergence in measure means that $\mu(\{x: \|f_n(x)-f(x)\| \geq \epsilon\}) \rightarrow 0$ as $n \rightarrow \infty$ for all $\epsilon > 0$. Convergence in $L^1$ implies convergence in measure, but not vice versa; a function that is Cauchy in measure is also convergent in measure and has a subsequence converging a.e. to the same function which is unique modulo a null set. Lastly, convergence a.e. on a finite measure space implies almost uniform convergence, and this implies a.e. convergence and convergence in measure.

Lastly, I'll return to the connection between premeasures, outer measures, and measures.
<details>
	<summary>Given some $\mathcal{E} \subset X$ and a function $\rho: \mathcal{E} \rightarrow [0,\infty]$ with some very basic restrictions, we can construct an outer measure from $\rho$.</summary>
	&emsp;We require that $\varnothing, X \in \mathcal{E}$ and $\rho(\varnothing) = 0$, and then if $A \subset X$, we can define \[\mu^*(A) = \inf \left\{ \sum_1^{\infty} \mu(E_j) : E_j \subset \mathcal{E} \text{ and } A \subset \bigcup_1^{\infty} E_j\right\}.\]
</details>
Now given a premeasure $\mu_0$ on an *algebra* $\mathcal{A}$, the above construction gives us a outer measure, the restriction of which on the $\sigma$-algebra generated by $\mathcal{A}$ leaves us with a measure $\mu$. If $\nu$ extends $\mu_0$, then $\nu(E) \leq \mu(E)$ for all $\mu$-measurable $E$, with equality when $\mu(E)$ is finite; also, if $\mu_0$ is $\sigma$-finite, then $\mu$ is unique. These last two facts are important in Folland's Exercise 3.12 which asks us to prove that if $\nu_j \ll \mu_j$ are $\sigma$-finite, then $\nu_1 \times \nu_2 \ll \mu_1 \times \mu_2$.

